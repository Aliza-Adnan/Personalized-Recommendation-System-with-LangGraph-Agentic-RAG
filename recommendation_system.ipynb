{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aRLCI42D-iXy",
    "outputId": "ff54fac1-4c6e-47a5-de77-f7c6d7fb7724"
   },
   "outputs": [],
   "source": [
    "# Install ctransformers and dependencies# Install dependencies (Colab-safe)\n",
    "!pip install -q ctransformers langgraph langchain faiss-cpu sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49d4buouUM8p",
    "outputId": "eb021972-a244-4ad6-ca3b-62fd51da99f3"
   },
   "outputs": [],
   "source": [
    "!pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 760,
     "referenced_widgets": [
      "767e8e16c70140c281fbd5ebf13e7751",
      "b4e0d8af554440db9b3870678f17a362",
      "5b4c95650db3442bab3dc5e8d31f6ae3",
      "7ac3e18ab0a34213bf1559d8ddc86956",
      "d4c68afb4ac14f16a1f2f2f5f591e475",
      "ece361ace31e452b8730f701bf64b38a",
      "327bb3da0bae45a1836b0769d029dead",
      "bbf695127c4448f2b460d24150e92bbf",
      "fab9b059ca5c45b7ba02d17f828bafaf",
      "ded3af34bfff4414a0acce5d26f7765f",
      "39e7bbfe900643b2b95e7deb59db0e43",
      "7993f274cc38485b866280c1ab961a7e",
      "f6b967a46d9f4e20b29ca22d7c29c379",
      "2037558c5c1e472a948b68f160ec78e2",
      "546b894392c943839a61ad59e64f4dd0",
      "6b0e925fba644655b763ae318362260f",
      "6b07eac5596f45b2a3fc6757ba5a58cc",
      "c2cfd69c1131424ca9d748ea7a24cd64",
      "c8fb20cf26b14596becbf4997e1ff2d9",
      "b244901d3bd9453a833b60257816cf67",
      "18beb34192644818b5be51a9f79d10dd",
      "a520d5a8ec6346108a8a54b7c9a299ae",
      "cab740c3215d4e6fa5d170181f68abd8",
      "fe3234db94b24f53a9f475ef6224d7dc",
      "440ff9a1972c49fc9cec44b901a809bb",
      "131a8f23823e46cea0ef48e5adc8691d",
      "e88cd052656b42f6918bd1a4fae1e217",
      "2c8ab5dffaba4d47901c959dfd92df73",
      "2965710f20c44fc082f3774b32ce7fe8",
      "815713fe89c94226b773a1ccad6a471e",
      "69f29a5fde654f07b104757bbaa703a9",
      "cd032300abfe44efab728ac7316c98c8",
      "bc7edbefafe644b2a05d4e09d734b1d7",
      "adb0edd5fbc3405aae82c5d27c52f6c5",
      "7477b2f5772b4c83a66479ab84797aa0",
      "06b76785f3c2417e92ca50a540cd7ae0",
      "6b21391dc32b4d899bcd3d4783e68da3",
      "8cdba1bae9fd468389067bc7039fd71c",
      "f75126948b2f46be982914193bed771f",
      "45c2a66dca7e412481d12aa7a4503047",
      "3ee39ac7d2d54903bb44f98464aea04c",
      "2cd7d2407c1e496592d1bffba3564b00",
      "c0aab679e9d74c879e736c944525dfb0",
      "1d9b941df65c49ecb80b539d37c6f521",
      "8d587e4cc613487d82de83129af7a900",
      "3843551d73884313a5e35da6cd5152ee",
      "2befac52345e4746b6fd95afbf18d1c0",
      "0e0599bb96d440518d31dbb6c3dec423",
      "80b34a1401cd4e6ba2669d11caf54380",
      "0012953c60914ca3be03202e4365d442",
      "cf3cce2f1f6942e091bbb1ecbda74eeb",
      "e095bf4ee4704f509c170b14b434d858",
      "33e77abbfdc247f8846ae18db50aa2ad",
      "7bd04b3ecf39406bba277b5865ac29fe",
      "9926cf325a9047e6aba01f1fe63dcb02",
      "70176df823524eaf88480a64472d8793",
      "aeba764d96a946c098a7cfa77b445679",
      "c6421b02a64d411c9fd6ed81bd98f7b8",
      "bf54074900c44b8c90f3137e05e2e6bf",
      "3e69ae9aa2484179bcfef45e81ceb514",
      "6a46f7fc054a436dab8adf2c75035241",
      "be115847e0c0450692e5a54e2955b95c",
      "1490f921fbdd4e98a1e5700476ebf91f",
      "e6f6138b9a99463fa7b6980c97def45c",
      "02ee19fe71f04691a1bb91297af3c0b1",
      "b9941e7b3bd34f5292b15a342fa8810c",
      "a21e0a69fe274b79911a17ec54e82992",
      "842f19374bcd46efa6aee3a44574a8f6",
      "5cb123e54b7041239685b31ba36d5d22",
      "860a01d74553454c8c60c7d7457f1c3c",
      "ba4890239d324c7aa84fa5514bff4a6e",
      "b8cddab512d4405993ada16cd9fe9417",
      "7cc3649cddf94c889fe066c02f021a2b",
      "d301709e82d247f4873b86333dac0c24",
      "d94ec6deb7ab4b9899978f251d10c54a",
      "90c82f49370a43cba507786e07073558",
      "9808ac895cd5435ab0eccc2048dcc302",
      "9a58b6934c81441ebc19a10b7baffd95",
      "9f5124bd01c84a56897fd57fd8a4e8bb",
      "a65bc88652464c51a657ad7d018f8144",
      "31ccba12679449799baaaad89c77ce1a",
      "4f5a5218841f42deb708516e5010ce8e",
      "d213b5550b2f4db4b65a6745d8f46989",
      "347e0f4af16a479fb456b39081a7e5db",
      "be42811409124c8990874b4868ee85df",
      "21354dd69ad8453a8a57fdfa92a0ca94",
      "6afda7e432834b2abfe3b9088e0b1ee1",
      "913657c98877405bbcdf202d0f644dc9",
      "ccc2b687b0da4fbca36befc2781ce3ae",
      "8d9777cb460345bc98c69cad6bd7339c",
      "b487f8eecd764800a8818104ba87569c",
      "12b367895d0348978915b655ea934a3b",
      "690e45b69ec14d558bd1fab9d491bc2f",
      "edf566208ad34bd486aaa873b6848a51",
      "206e3d568a204d24871841fc0b3bf856",
      "b720799715bb41309bceca3c85db14e8",
      "83dc9efb94794e5bb62d7f7435ad6a37",
      "f1c3a98b41e14785b4966d3323587e9e",
      "d1d7fe7eff6d4e1d909bb949ebfed137",
      "d5ad0aa7f8fc453489c3eabac57b7b61",
      "f69ea6597a6d4045b179e90110680b44",
      "8f23eae42dca4a56860fc6241db986e4",
      "49615c7d85a74f788675f3dc8dd6f49c",
      "6a6173f9b6e74e23a3fb9b83a1009aa2",
      "4b707c871b914939b5aef0a46deecfe5",
      "bf48be8fad194513807c78a8e254b689",
      "d09e29219e1a4674b2eac2ac65423fbd",
      "2373430ada534f949de7a228f1cb298e",
      "38f5858907184fbf9ee4388c639afd32",
      "a38270b28941416080af4261e0938e01",
      "ca600f422d9543a18b1f5110473d84ee",
      "0f5268c054234eebb28caf979822fa82",
      "31c4bb8c4d1a48d4b9d083132a71ac7a",
      "a1880851f1ae4bf5a4094f8e1334ee8c",
      "c0a715ff7a6d4bbfbc0f9acde0429f65",
      "0cff750f22c447d38c0e07b8fefe18ad",
      "c4ef545062ae4de781ee720ff3dba791",
      "381bb975e7c14610a515335db6e525a9",
      "ec7614617f28403e8fdaa1a8f39a90d4",
      "2f1a91d24f6a42b2a8bd4cf28fab6428",
      "2165d230638b4d98859e2c2791733450",
      "339542dd6adf4a708d4459fbb76f6a37",
      "73a5247e6ee24062a6e5731c7d082719",
      "cf0df2364d2948f199a691d7ee4c02ff",
      "c66c10c0dc444f89b83b4062cf96b9c4",
      "25fb8ddf44944cfe9ddb1346c9619fd1",
      "297ecc2411ba4eee923180d8d2027a29",
      "e37afa51c7544c19ab94bf9b663611f7",
      "372056d6517746d7b5570e81499f5d43",
      "5b78b7cf65b34602a1ccc189adf9cee2",
      "dadcaa600f1545f1ad016724bec9d766",
      "9b25143b478d457b8b0bd393734987c4",
      "b6c614bc6be941e488334934383c6269",
      "157c7ab8848445d79745f46bb26ca780",
      "27190f37e43042f6af66ecc245e8b4e2",
      "28a609b424884388a50f89de479a8629",
      "a814791c057d4d469a8ad2948a447a3b",
      "8eea87acc3244bd9977b3780de796b85",
      "5275a8955ed944a28240f2b74ee70efa",
      "c9e2cd92664f4ebfaaf6129eb589e803",
      "fca793fc8a1c4e3dbc79f8e19004e791",
      "5ec4ea2581974ea085d11da1b71b8a04",
      "bc7d3e93178940aeabfcd55a15c0b8a8",
      "1ae585f5aa084094afad7477dff03f48",
      "f758d0ee64f54cecaa6af49abed06937",
      "46cbbf87387741eca0e4cf7dc868a42a",
      "fb0990a5d780416980421b22ab48a7f0",
      "4d045e49609440a493fcb245b7f17774",
      "68b7e2e558bb4853a174e379654e0bd3",
      "4b5638e0501341b19270c1abef5c25dd",
      "eb6252a56c954e39b20ed796e7f23d14",
      "09fd54dc8850400d8b2cd5e777002551",
      "3be3967b64b44abe87c7e591114b4525",
      "cccf1b4939fb4dfb8d9836b71de09a7b",
      "ef05bf3886cb4278894c478b2b00810b",
      "e95a6c30aec847f392efb79e404983cd",
      "cae294e3237e4d219cb0e6436de85a4e",
      "6b41ecc977f8440b870b7b714a959028",
      "a35f7ae2cabe4fd59956752dc49db965",
      "599c55fce4df4f719c6048a6f75de357",
      "1d773d01c2524d36bf723fa33c17fd33",
      "d444477fc53441d5940dae332e691e02",
      "01e55a5368c3466d907c057a06169654",
      "c7c03338a9a74b76a7391d04874a306d",
      "d9947ae6b0764cbdae7ac0cb16889903"
     ]
    },
    "id": "zP1VZgiA-ePO",
    "outputId": "92c0da66-017f-4257-b7c4-879c03883031"
   },
   "outputs": [],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Literal, List\n",
    "\n",
    "# Load quantized LLM using ctransformers (fast and CPU-friendly)\n",
    "llm = AutoModelForCausalLM.from_pretrained(\n",
    "    \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\",\n",
    "    model_file=\"mistral-7b-instruct-v0.2.Q4_K_M.gguf\",\n",
    "    model_type=\"mistral\",\n",
    "    context_length=2048,\n",
    "    gpu_layers=0  # CPU only\n",
    ")\n",
    "\n",
    "# Documents: You can replace with your own domain-specific data\n",
    "docs = [\n",
    "    \"User A enjoys science fiction and prefers short books.\",\n",
    "    \"Book: Dune – A classic sci-fi epic.\",\n",
    "    \"Book: Project Hail Mary – A fast-paced science fiction novel.\",\n",
    "    \"Book: The Hobbit – A short fantasy story with adventure.\",\n",
    "    \"Book: Foundation – A legendary sci-fi series by Isaac Asimov.\",\n",
    "    \"User B enjoys romance and character-driven narratives.\",\n",
    "    \"Book: Pride and Prejudice – A romantic classic.\",\n",
    "    \"Book: The Notebook – A deeply emotional romance.\",\n",
    "]\n",
    "\n",
    "# Vector store (RAG backend)\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=0)\n",
    "faiss_docs = splitter.create_documents(docs)\n",
    "vectorstore = FAISS.from_documents(faiss_docs, embedding)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# LangGraph Agent State\n",
    "class AgentState(TypedDict):\n",
    "    user_query: str\n",
    "    retrieved_docs: List[str]\n",
    "    final_response: str\n",
    "    next_action: Literal[\"retrieve\", \"reason\", \"end\"]\n",
    "\n",
    "# Planner Node (decides what to do)\n",
    "def planner_node(state: AgentState) -> AgentState:\n",
    "    if not state.get(\"retrieved_docs\"):\n",
    "        next_action = \"retrieve\"\n",
    "    elif state.get(\"final_response\"):  # Already has a response\n",
    "        next_action = \"end\"\n",
    "    else:\n",
    "        next_action = \"reason\"\n",
    "    return {**state, \"next_action\": next_action}\n",
    "\n",
    "\n",
    "# Retrieval Tool\n",
    "def retrieval_node(state: AgentState) -> AgentState:\n",
    "    docs = retriever.get_relevant_documents(state[\"user_query\"])\n",
    "    return {\n",
    "        **state,\n",
    "        \"retrieved_docs\": [doc.page_content for doc in docs],\n",
    "        \"next_action\": \"reason\"\n",
    "    }\n",
    "\n",
    "# Reasoning Tool (LLM)\n",
    "def reasoning_node(state: AgentState) -> AgentState:\n",
    "    context = \"\\n\".join(state[\"retrieved_docs\"])\n",
    "    prompt = f\"\"\"You are a recommendation system.\n",
    "\n",
    "Only use the information from the context below to answer the user. Do not use any external knowledge.\n",
    "\n",
    "User Query:\n",
    "{state['user_query']}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Answer with a personalized recommendation using only the above context.\n",
    "\"\"\"\n",
    "    response = llm(prompt)\n",
    "    return {\n",
    "        **state,\n",
    "        \"final_response\": response.strip(),\n",
    "        \"next_action\": \"end\"\n",
    "    }\n",
    "\n",
    "# LangGraph Agentic Flow\n",
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(\"planner\", planner_node)\n",
    "builder.add_node(\"retrieve\", retrieval_node)\n",
    "builder.add_node(\"reason\", reasoning_node)\n",
    "\n",
    "builder.set_entry_point(\"planner\")\n",
    "\n",
    "builder.add_conditional_edges(\"planner\", lambda s: s[\"next_action\"], {\n",
    "    \"retrieve\": \"retrieve\",\n",
    "    \"reason\": \"reason\",\n",
    "    \"end\": END\n",
    "})\n",
    "\n",
    "builder.add_edge(\"retrieve\", \"planner\")\n",
    "builder.add_edge(\"reason\", \"planner\")\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# Run the agent\n",
    "query = \"Can you suggest a fast sci-fi book for someone who likes short stories?\"\n",
    "result = graph.invoke({\"user_query\": query})\n",
    "\n",
    "print(\"🤖 Final Answer:\")\n",
    "print(result[\"final_response\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTl3sXcsMlz9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
